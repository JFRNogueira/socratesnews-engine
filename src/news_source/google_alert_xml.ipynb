{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import re\n",
    "\n",
    "%run \"./news_source/news.ipynb\" import News\n",
    "\n",
    "%run \"./jgc_news/g1.ipynb\" import G1\n",
    "# %run \"../jgc_news/dn.ipynb\" import DN\n",
    "# %run \"../jgc_news/odia.ipynb\" import ODia\n",
    "# %run \"../jgc_news/estadao.ipynb\" import Estadao\n",
    "# %run \"../jgc_news/folha.ipynb\" import Folha\n",
    "# %run \"../jgc_news/espn.ipynb\" import Espn\n",
    "# %run \"../jgc_news/uol.ipynb\" import Uol\n",
    "# %run \"../jgc_news/correio_braziliense.ipynb\" import CorreioBraziliense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleAlertXml:\n",
    "\n",
    "    def __init__(self, newsSource, sectionId, sectionName, sectionArr, tags):\n",
    "        self.newsSource = newsSource\n",
    "        self.sectionId = sectionId\n",
    "        self.sectionName = sectionName\n",
    "        self.sectionArr = sectionArr\n",
    "        self.tags = tags\n",
    "        \n",
    "        self.xml_soup = self.get_xml()\n",
    "        self.title_xml = self.get_title_xml()\n",
    "        self.news_metadata = self.get_news_metadata()\n",
    "        # self.source = self.get_source(self.newsSource)\n",
    "        # self.hours_since_published = self.get_until_now()\n",
    "        # self.newsData = self.get_news_data()\n",
    "\n",
    "\n",
    "    def get_xml(self):\n",
    "        browsers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome / 86.0.4240.198Safari / 537.36\"}\n",
    "        xml_content = requests.get(self.newsSource, headers = browsers)\n",
    "        soup = BeautifulSoup(xml_content.text, 'xml')\n",
    "        return soup\n",
    "    \n",
    "    \n",
    "    def get_title_xml(self):\n",
    "        title = self.xml_soup.find('title').get_text()\n",
    "        return title.split(sep=' - ')[1]\n",
    "    \n",
    "    \n",
    "    def get_until_now(self):\n",
    "        ts_str = self.xml_soup.find('published').get_text()\n",
    "        date_time_obj = datetime.strptime(ts_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        date_time_obj = date_time_obj.replace(tzinfo=timezone.utc)\n",
    "        current_time = datetime.now(timezone.utc)\n",
    "        time_difference = current_time - date_time_obj\n",
    "        hours_passed = time_difference.total_seconds() / 3600\n",
    "        return hours_passed\n",
    "    \n",
    "    \n",
    "    def get_source(self, url):\n",
    "        if 'tntsports.com.br' in url:\n",
    "            return 'tntsports'\n",
    "        if 'correiobraziliense.com.br' in url:\n",
    "            return 'correiobraziliense'\n",
    "        if 'placar.com.br' in url:\n",
    "            return 'placar'\n",
    "        if 'flamengo.com.br' in url:\n",
    "            return 'flamengo'\n",
    "        if 'agoracomvoce.com.br' in url:\n",
    "            return 'agoracomvoce'\n",
    "        if 'folhape.com.br' in url:\n",
    "            return 'folhape'\n",
    "        if 'espn.com.br' in url:\n",
    "            return 'espn'\n",
    "        if 'uol.com.br' in url:\n",
    "            return 'uol'\n",
    "        if 'ge.globo.com' in url:\n",
    "            return 'geglobo'\n",
    "        return 'outro'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_news_metadata(self):\n",
    "        result = []\n",
    "        news_all = self.xml_soup.find_all('entry')\n",
    "        for news in news_all:\n",
    "            title = news.find('title').get_text()\n",
    "            url = news.find('link').get('href')\n",
    "            source = self.get_source(url)\n",
    "            timestamp = news.find('published').get_text()\n",
    "            result += [News(source, url, title, timestamp)]\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
